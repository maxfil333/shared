{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60c8146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021d9eef",
   "metadata": {},
   "source": [
    "### dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61efea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_wine(as_frame=True)\n",
    "\n",
    "pandas_df = data['data']\n",
    "targets= data['target']\n",
    "\n",
    "display(pandas_df.head())\n",
    "display(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f748f4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df = scaler.fit_transform(pandas_df.to_numpy())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, targets, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99519821",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_X_train = torch.from_numpy(X_train).to(torch.float32)\n",
    "tensor_y_train = torch.from_numpy(y_train.to_numpy()).to(torch.int8)\n",
    "\n",
    "display(tensor_X_train)\n",
    "display(tensor_X_train.shape)\n",
    "display(tensor_y_train)\n",
    "display(tensor_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0699fa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(tensor_X_train, tensor_y_train)\n",
    "for i in train_dataset:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdeac9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "for i in train_dataloader:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124b41d4",
   "metadata": {},
   "source": [
    "### model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab0a8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(13, 32), \n",
    "                      nn.ReLU(), \n",
    "                      nn.Linear(32, 32),\n",
    "                      nn.ReLU(), \n",
    "                      nn.Linear(32,3))\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850b7f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ca0e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "\n",
    "for epoch in tqdm.tqdm(range(epochs)):\n",
    "    for x, y in train_dataloader:\n",
    "        outputs = model(x)\n",
    "        tgs = y.to(torch.long)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, tgs)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0420478b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(train_dataset[0][0].unsqueeze(dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a460f0c8",
   "metadata": {},
   "source": [
    "### eval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feab2769",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    result = model(torch.from_numpy(X_test).to(torch.float32))\n",
    "    \n",
    "result[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc79be85",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(result, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e6f025",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.from_numpy(y_test.to_numpy()).to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9897e01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(result, dim=1) == torch.from_numpy(y_test.to_numpy()).to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f88c60f-03c8-4b2a-8b05-97b0dc26e9ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a80cd20-b0e1-4e29-8119-cae3de578766",
   "metadata": {},
   "source": [
    "# LeNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fe0dd31c-7ad0-4c8d-b1a5-582b3eed0c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "30b7177c-235b-43d2-871b-aea7d972e4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d = Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a7779a6-24d3-4132-a95d-a376e5c94b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "    # C1 (1@32×32 → 6@28×28 → 6@14×14)\n",
    "    nn.Conv2d(1, 6, 5),\n",
    "    nn.Tanh(),\n",
    "    nn.AvgPool2d(2, 2),\n",
    "\n",
    "    # C3 (6@14×14 → 16@10×10 → 16@5×5)\n",
    "    nn.Conv2d(6, 16, 5),\n",
    "    nn.Tanh(),\n",
    "    nn.AvgPool2d(2, 2),\n",
    "\n",
    "\t# C5 записанный в виде полносвязного слоя вместо свертки\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16 * 5 * 5, 120),\n",
    "    nn.Tanh(),\n",
    "    \n",
    "    nn.Linear(120, 84),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(84, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee51ea07-6a13-49b3-a734-c491572ac813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchsummary\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6de74997-16b8-45af-a6fa-83907f1dd34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             156\n",
      "              Tanh-2            [-1, 6, 28, 28]               0\n",
      "         AvgPool2d-3            [-1, 6, 14, 14]               0\n",
      "            Conv2d-4           [-1, 16, 10, 10]           2,416\n",
      "              Tanh-5           [-1, 16, 10, 10]               0\n",
      "         AvgPool2d-6             [-1, 16, 5, 5]               0\n",
      "           Flatten-7                  [-1, 400]               0\n",
      "            Linear-8                  [-1, 120]          48,120\n",
      "              Tanh-9                  [-1, 120]               0\n",
      "           Linear-10                   [-1, 84]          10,164\n",
      "             Tanh-11                   [-1, 84]               0\n",
      "           Linear-12                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.11\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.35\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(1,32,32), device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa93c9e7-2449-4946-aabd-f1e26f80a24c",
   "metadata": {},
   "source": [
    "# Torch | cv2 | PIL | convertations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0dfd5ea9-1618-4067-8344-4f332b2970b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "\n",
    "import numpy as np\n",
    "import cv2 \n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7684c8e2-c53f-42ca-aac2-3e226775fead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2160, 3840, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_img_bgr = cv2.imread('jinx.jpg')\n",
    "cv_img_rgb = cv2.cvtColor(cv_img_bgr, cv2.COLOR_BGR2RGB)\n",
    "cv_img_rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b170682-384b-4525-8e9f-17069d1c53f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_array_to_tensor1(rgb: np.ndarray) -> torch.Tensor:\n",
    "    # H, W, C -> C, H, W\n",
    "    tensor = torch.from_numpy(rgb).permute(2, 0, 1).float()\n",
    "    # Нормализуем и добавляем батч\n",
    "    return (tensor / 255.0).unsqueeze(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c88c1d8-99e4-417f-80d4-e4994cbc28e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 2160, 3840])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_array_to_tensor1(cv_img_rgb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a74d560e-fddc-48e7-8b52-08efda4355f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "i1 = rgb_array_to_tensor1(cv_img_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1a6fb53-e00c-4440-9f15-1c589c688071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_array_to_tensor2(rgb: np.ndarray) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Преобразует RGB-изображение из numpy-массива в тензор PyTorch\n",
    "    H,W,C -> C,H,W, нормализация к [0,1], добавление batch.\n",
    "    \"\"\"\n",
    "    # permute + float + /255\n",
    "    tensor = to_tensor(rgb)  # -> [3, H, W]\n",
    "    # Добавляем batch dimension\n",
    "    return tensor.unsqueeze(0)  # -> [1, 3, H, W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83193295-311b-472d-b156-3f350afc6952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 2160, 3840])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_array_to_tensor2(cv_img_rgb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f6924e7-6510-4702-af84-779a93921fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "i2 = rgb_array_to_tensor2(cv_img_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2166f169-eb78-4c7b-9ab6-6774d111a9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(i1 == i2).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f1877b09-402b-4d36-a193-bc919b3afd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_rgb_array(tensor: torch.Tensor) -> np.ndarray:\n",
    "    \n",
    "    if tensor.ndim == 4:\n",
    "        tensor = tensor.squeeze(0)\n",
    "    if tensor.ndim != 3 or tensor.shape[0] != 3:\n",
    "        raise ValueError(f\"Ожидается [3, H, W], получено: {tensor.shape}\")\n",
    "\n",
    "    tensor = tensor.mul(255.0)\n",
    "    tensor = torch.clamp(tensor, 0, 255)\n",
    "    tensor = tensor.to(torch.uint8)\n",
    "    tensor = tensor.permute(1, 2, 0) # C,H,W -> H,W,C (RGB)\n",
    "    return tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b43f45d2-c711-44eb-abe5-b4e19451ccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = nn.AvgPool2d(kernel_size=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3060c039-b5b9-4172-ab53-eda05008e693",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_img = pool(i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5195ff4-dc3f-470c-b257-6afb87ffeaed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 196, 349])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "782581ee-db37-44c5-a7c0-d86d63fbfeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_img = tensor_to_rgb_array(pooled_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "08128bfc-06d4-448e-bff8-2fd10849a9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(out_img).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803bfd42-364d-489f-926f-b4457a7538ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
